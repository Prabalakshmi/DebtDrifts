{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install snscrape\n",
    "\n",
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aaecb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "# # Fetching tweets and putting it into a dataframe and csv file\n",
    "\n",
    "# import snscrape.modules.twitter as sntwitter\n",
    "# import pandas as pd\n",
    "\n",
    "# #query = \"(from:elonmusk) until:2020-01-01 since:2010-01-01\"\n",
    "\n",
    "# # input hashtag you want to search here\n",
    "# query = \"(#studentloanforgiveness) until:2022-10-24 since:2022-09-24\"\n",
    "# tweets = []\n",
    "# # number of tweets we need\n",
    "# limit = 100\n",
    "\n",
    "\n",
    "# for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "#     # print(vars(tweet))\n",
    "#     # break\n",
    "    \n",
    "#     #input your location here\n",
    "    \n",
    "#     if tweet.user.location!='United States':\n",
    "#         continue\n",
    "#     if len(tweets) == limit:\n",
    "#         break\n",
    "#     else:\n",
    "#         # tweet id\n",
    "#         # print(tweet.id)\n",
    "#         tweets.append([tweet.date, tweet.user.username, tweet.user.id, tweet.content, tweet.user.location, tweet.user.profileImageUrl])\n",
    "        \n",
    "        \n",
    "# df = pd.DataFrame(tweets, columns=['Date', 'User Name', 'User ID', 'Tweet', 'Location', 'Image URL'])\n",
    "# #print(df)\n",
    "# df.to_csv('sample_data.csv')\n",
    "# print(\"Process completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(tweets, columns=['Date', 'User Name', 'User ID', 'Tweet', 'Location', 'Image URL'])\n",
    "# #print(df)\n",
    "# df.to_csv('fff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ec8d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 1000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 1500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 2000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 2500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 3000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 3500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 4000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 4500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 5000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 5500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 6000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 6500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 7000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 7500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 8000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 8500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 9000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 9500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 10000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 10500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 11000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 11500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 12000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 12500 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fetched 13000 tweets so far\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process halted after fetching 13191 tweets\n"
     ]
    }
   ],
   "source": [
    "# Fetching tweets and putting it into a dataframe and csv file\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "#query = \"(from:elonmusk) until:2020-01-01 since:2010-01-01\"\n",
    "\n",
    "# input hashtag you want to search here\n",
    "query = \"(#studentloanforgiveness) until:2022-12-07 since:2022-09-15\"\n",
    "tweets = []\n",
    "# number of tweets we need\n",
    "limit = 100000\n",
    "\n",
    "i = 1\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\"Fetched\", i, \"tweets so far\")\n",
    "        print('-'*100)\n",
    "        \n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    \n",
    "    i += 1    \n",
    "   \n",
    "    tweets.append([tweet.date, tweet.user.username, tweet.user.id, tweet.content, tweet.user.location, tweet.user.profileImageUrl])\n",
    "        \n",
    "print('Process halted after fetching', len(tweets), 'tweets')        \n",
    "df_studentloanforgiveness = pd.DataFrame(tweets, columns=['Date', 'User Name', 'User ID', 'Tweet', 'User Location', 'Image URL'])\n",
    "#print(df)\n",
    "# df_studentloanforgiveness.to_csv('student_loan_forgiveness.csv')\n",
    "# print(\"Process completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49feeeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "df_studentloanforgiveness.to_csv('student_loan_forgiveness.csv')\n",
    "print(\"Process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483e8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdb80f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User Name</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>User Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-08 04:10:58+00:00</td>\n",
       "      <td>KLudsey</td>\n",
       "      <td>1600675031587192833</td>\n",
       "      <td>9 million people got incorrect email about 'ap...</td>\n",
       "      <td></td>\n",
       "      <td>https://abs.twimg.com/sticky/default_profile_i...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-08 04:04:47+00:00</td>\n",
       "      <td>ShittyJesus</td>\n",
       "      <td>870033934838452225</td>\n",
       "      <td>The argument of \"we took the PPP loans knowing...</td>\n",
       "      <td>In the lego you stepped on</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/870712806...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-08 03:17:42+00:00</td>\n",
       "      <td>scottandrewh</td>\n",
       "      <td>79532585</td>\n",
       "      <td>Whoever coined the phrase \"do what you love, a...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/548641232...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-08 02:32:47+00:00</td>\n",
       "      <td>pumpkinstench</td>\n",
       "      <td>50763295</td>\n",
       "      <td>@SenSchumer Big things except #studentloanforg...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/758470995...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-08 01:50:03+00:00</td>\n",
       "      <td>moneytalksdocu</td>\n",
       "      <td>1376587864549494796</td>\n",
       "      <td>What's your student loan story? Share yours he...</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/137775044...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2022-12-01 14:22:16+00:00</td>\n",
       "      <td>hss25</td>\n",
       "      <td>133515273</td>\n",
       "      <td>#GinniThomas should be in jail w/the other idi...</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/110673423...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022-12-01 14:21:44+00:00</td>\n",
       "      <td>jprince_cheryl</td>\n",
       "      <td>736004984</td>\n",
       "      <td>Appeals Court Denies Biden’s Bid to Revive Stu...</td>\n",
       "      <td>859, KY</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/930561465...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2022-12-01 14:15:45+00:00</td>\n",
       "      <td>AngryIrishman37</td>\n",
       "      <td>838932282752843776</td>\n",
       "      <td>How many people were suckered into voting Dem ...</td>\n",
       "      <td>Peoples Republic of Maryland</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/108462167...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2022-12-01 14:10:52+00:00</td>\n",
       "      <td>BobbyFreedom1</td>\n",
       "      <td>1255707061</td>\n",
       "      <td>Looks like @joebiden's ass keeps writing check...</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/349883023...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2022-12-01 14:08:04+00:00</td>\n",
       "      <td>jkads35</td>\n",
       "      <td>4140688761</td>\n",
       "      <td>Imagine living in a country that bails out and...</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/150551796...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date        User Name              User ID  \\\n",
       "0   2022-12-08 04:10:58+00:00          KLudsey  1600675031587192833   \n",
       "1   2022-12-08 04:04:47+00:00      ShittyJesus   870033934838452225   \n",
       "2   2022-12-08 03:17:42+00:00     scottandrewh             79532585   \n",
       "3   2022-12-08 02:32:47+00:00    pumpkinstench             50763295   \n",
       "4   2022-12-08 01:50:03+00:00   moneytalksdocu  1376587864549494796   \n",
       "..                        ...              ...                  ...   \n",
       "495 2022-12-01 14:22:16+00:00            hss25            133515273   \n",
       "496 2022-12-01 14:21:44+00:00   jprince_cheryl            736004984   \n",
       "497 2022-12-01 14:15:45+00:00  AngryIrishman37   838932282752843776   \n",
       "498 2022-12-01 14:10:52+00:00    BobbyFreedom1           1255707061   \n",
       "499 2022-12-01 14:08:04+00:00          jkads35           4140688761   \n",
       "\n",
       "                                                 Tweet  \\\n",
       "0    9 million people got incorrect email about 'ap...   \n",
       "1    The argument of \"we took the PPP loans knowing...   \n",
       "2    Whoever coined the phrase \"do what you love, a...   \n",
       "3    @SenSchumer Big things except #studentloanforg...   \n",
       "4    What's your student loan story? Share yours he...   \n",
       "..                                                 ...   \n",
       "495  #GinniThomas should be in jail w/the other idi...   \n",
       "496  Appeals Court Denies Biden’s Bid to Revive Stu...   \n",
       "497  How many people were suckered into voting Dem ...   \n",
       "498  Looks like @joebiden's ass keeps writing check...   \n",
       "499  Imagine living in a country that bails out and...   \n",
       "\n",
       "                         Location  \\\n",
       "0                                   \n",
       "1      In the lego you stepped on   \n",
       "2                    New York, NY   \n",
       "3                      Texas, USA   \n",
       "4                                   \n",
       "..                            ...   \n",
       "495                     Tampa, FL   \n",
       "496                      859, KY    \n",
       "497  Peoples Republic of Maryland   \n",
       "498                                 \n",
       "499                                 \n",
       "\n",
       "                                             Image URL  User Location  \n",
       "0    https://abs.twimg.com/sticky/default_profile_i...  United States  \n",
       "1    https://pbs.twimg.com/profile_images/870712806...  United States  \n",
       "2    https://pbs.twimg.com/profile_images/548641232...  United States  \n",
       "3    https://pbs.twimg.com/profile_images/758470995...  United States  \n",
       "4    https://pbs.twimg.com/profile_images/137775044...  United States  \n",
       "..                                                 ...            ...  \n",
       "495  https://pbs.twimg.com/profile_images/110673423...  United States  \n",
       "496  https://pbs.twimg.com/profile_images/930561465...  United States  \n",
       "497  https://pbs.twimg.com/profile_images/108462167...  United States  \n",
       "498  https://pbs.twimg.com/profile_images/349883023...  United States  \n",
       "499  https://pbs.twimg.com/profile_images/150551796...  United States  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_studentloanforgiveness['Location'] = 'United States'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching tweets and putting it into a dataframe and csv file\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "#query = \"(from:elonmusk) until:2020-01-01 since:2010-01-01\"\n",
    "\n",
    "# input hashtag you want to search here\n",
    "query = \"#studentdebtbomb\"\n",
    "tweets = []\n",
    "# number of tweets we need\n",
    "limit = 75000\n",
    "\n",
    "i = 0\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "    i += 1    \n",
    "    if i % 500 == 0:\n",
    "        print(\"Fetched\", i, \"tweets so far\")\n",
    "        print('-'*80)\n",
    "    \n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "\n",
    "    tweets.append([tweet.date, tweet.user.username, tweet.user.id, tweet.content, tweet.user.location, tweet.user.profileImageUrl])\n",
    "        \n",
    "print('Process halted after fetching', i, 'tweets')        \n",
    "df_studentloanforgiveness = pd.DataFrame(tweets, columns=['Date', 'User Name', 'User ID', 'Tweet', 'Location', 'Image URL'])\n",
    "#print(df)\n",
    "# df.to_csv('sample_data.csv')\n",
    "# print(\"Process completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa65cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4e1b76",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 tweets so far\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "GeocoderUnavailable",
     "evalue": "HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=New+York%2C+LA%2C+Houston&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 440\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    812\u001b[0m     )\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    814\u001b[0m         method,\n\u001b[0;32m    815\u001b[0m         url,\n\u001b[0;32m    816\u001b[0m         body,\n\u001b[0;32m    817\u001b[0m         headers,\n\u001b[0;32m    818\u001b[0m         retries,\n\u001b[0;32m    819\u001b[0m         redirect,\n\u001b[0;32m    820\u001b[0m         assert_same_host,\n\u001b[0;32m    821\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    822\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    823\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    824\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    825\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    812\u001b[0m     )\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    814\u001b[0m         method,\n\u001b[0;32m    815\u001b[0m         url,\n\u001b[0;32m    816\u001b[0m         body,\n\u001b[0;32m    817\u001b[0m         headers,\n\u001b[0;32m    818\u001b[0m         retries,\n\u001b[0;32m    819\u001b[0m         redirect,\n\u001b[0;32m    820\u001b[0m         assert_same_host,\n\u001b[0;32m    821\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    822\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    823\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    824\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    825\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=New+York%2C+LA%2C+Houston&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\geopy\\adapters.py:457\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:542\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=New+York%2C+LA%2C+Houston&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGeocoderUnavailable\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \n\u001b[0;32m     37\u001b[0m     \n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#geolocator = Nominatim(user_agent=user_agent)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m#geocode = partial(geolocator.geocode, language=\"en\",timeout=1000000)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     d\u001b[38;5;241m=\u001b[39m\u001b[43mgeocode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(d)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\geopy\\geocoders\\nominatim.py:297\u001b[0m, in \u001b[0;36mNominatim.geocode\u001b[1;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[0;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, url)\n\u001b[0;32m    296\u001b[0m callback \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json, exactly_one\u001b[38;5;241m=\u001b[39mexactly_one)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_geocoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\geopy\\geocoders\\base.py:368\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[1;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[1;32m--> 368\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_text(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\geopy\\adapters.py:447\u001b[0m, in \u001b[0;36mRequestsAdapter.get_json\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[1;32m--> 447\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\geopy\\adapters.py:469\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GeocoderServiceError(message)\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GeocoderUnavailable(message)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, requests\u001b[38;5;241m.\u001b[39mTimeout):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GeocoderTimedOut(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mGeocoderUnavailable\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=New+York%2C+LA%2C+Houston&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import time\n",
    "import tweepy\n",
    "import configparser\n",
    "from functools import partial\n",
    "from geopy.geocoders import Nominatim\n",
    "start_time=time.time()\n",
    "#query = \"(from:elonmusk) until:2020-01-01 since:2010-01-01\"\n",
    "#query = \"(#rishisunak) until:2022-09-06 since:2022-07-01\"\n",
    "query=\"(#studentloanforgiveness) until:2022-10-24 since:2022-09-24\"\n",
    "tweets = []\n",
    "limit = 10000\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "#config.read('config.txt')\n",
    "\n",
    "#countries_list=['Netherlands','India','Andorra','Greece','Serbia','Germany','Switzerland','Slovakia','Belgium', 'Romania', 'Hungary', 'Moldova', 'Denmark', 'Ireland', 'Finland', 'Ukraine', 'Portugal', 'Slovenia', 'United Kingdom', 'Luxembourg', 'Spain', 'Belarus', 'Monaco', 'Russia', 'Cyprus', 'Greenland', 'Norway', 'France', 'Montenegro', 'Czech Republic', 'Iceland', 'Latvia', 'Italy', 'San Marino', 'Bosnia & Herzegovina', 'North Macedonia', 'Bulgaria', 'Sweden', 'Estonia', 'Albania', 'Liechtenstein', 'Malta', 'Holy See', 'Austria', 'Lithuania', 'Poland', 'Croatia']\n",
    "# countries_list=['India']\n",
    "\n",
    "user_agent='Data Mining'\n",
    "geolocator = Nominatim(user_agent=user_agent)\n",
    "geocode = partial(geolocator.geocode, language=\"en\")\n",
    "\n",
    "i=0\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "    # print(vars(tweet))\n",
    "    # break\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    if tweet.user.location=='':\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        #geolocator = Nominatim(user_agent=user_agent)\n",
    "        #geocode = partial(geolocator.geocode, language=\"en\",timeout=1000000)\n",
    "        \n",
    "        d=geocode(tweet.user.location)\n",
    "        a=str(d).split(',')\n",
    "        \n",
    "        if a[-1]=='None':\n",
    "            continue\n",
    "        #if a[-1] not in countries_list:\n",
    "         #   continue\n",
    "        #print(i)\n",
    "        i=i+1\n",
    "        if i % 100 == 0:\n",
    "            print(\"Fetched\", i, \"tweets so far\")\n",
    "            print('-'*80)\n",
    "        tweets.append([tweet.id, tweet.date, tweet.user.username, tweet.content, tweet.user.location, a[-1], tweet.user.profileImageUrl])\n",
    "\n",
    "print(\"Total tweets scraped -\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84768f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(tweets, columns=['User ID', 'Date', 'User Name', 'Tweet', 'Location', 'Country', 'Image URL'])\n",
    "#print(df)\n",
    "df.to_csv('sample_data.csv')\n",
    "print(\"Process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64685701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User Name</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-23 23:43:33+00:00</td>\n",
       "      <td>unrealElunMosk</td>\n",
       "      <td>1396132870570352648</td>\n",
       "      <td>If you want your #studentloanforgiveness you b...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/139613309...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-23 23:43:08+00:00</td>\n",
       "      <td>kevinpost</td>\n",
       "      <td>8909302</td>\n",
       "      <td>@GlennKesslerWP @ddale8 @PolitiFact \\nYou all ...</td>\n",
       "      <td>Highland Park, TX</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159047739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-23 23:15:32+00:00</td>\n",
       "      <td>5731965i</td>\n",
       "      <td>819019776844513280</td>\n",
       "      <td>@IAGovernor THIS IS A DISTRACTION. LETS TALK A...</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/879123411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-23 23:13:41+00:00</td>\n",
       "      <td>Flyonth85407338</td>\n",
       "      <td>986685548612980736</td>\n",
       "      <td>@FoxNews The question the interviewer didn't a...</td>\n",
       "      <td></td>\n",
       "      <td>https://pbs.twimg.com/profile_images/986696636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-23 23:04:06+00:00</td>\n",
       "      <td>TuscaloosaDems</td>\n",
       "      <td>47017680</td>\n",
       "      <td>Dark Brandon administration’s student loan rel...</td>\n",
       "      <td>Tuscaloosa, Alabama</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/157443155...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date        User Name              User ID  \\\n",
       "0 2022-10-23 23:43:33+00:00   unrealElunMosk  1396132870570352648   \n",
       "1 2022-10-23 23:43:08+00:00        kevinpost              8909302   \n",
       "2 2022-10-23 23:15:32+00:00         5731965i   819019776844513280   \n",
       "3 2022-10-23 23:13:41+00:00  Flyonth85407338   986685548612980736   \n",
       "4 2022-10-23 23:04:06+00:00   TuscaloosaDems             47017680   \n",
       "\n",
       "                                               Tweet             Location  \\\n",
       "0  If you want your #studentloanforgiveness you b...           Austin, TX   \n",
       "1  @GlennKesslerWP @ddale8 @PolitiFact \\nYou all ...    Highland Park, TX   \n",
       "2  @IAGovernor THIS IS A DISTRACTION. LETS TALK A...                        \n",
       "3  @FoxNews The question the interviewer didn't a...                        \n",
       "4  Dark Brandon administration’s student loan rel...  Tuscaloosa, Alabama   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://pbs.twimg.com/profile_images/139613309...  \n",
       "1  https://pbs.twimg.com/profile_images/159047739...  \n",
       "2  https://pbs.twimg.com/profile_images/879123411...  \n",
       "3  https://pbs.twimg.com/profile_images/986696636...  \n",
       "4  https://pbs.twimg.com/profile_images/157443155...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13cda562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing\n",
    "\n",
    "# # import stopwords\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # import textblob\n",
    "# from textblob import Word, TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a80baf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Arunaggiri\n",
      "[nltk_data]     Pandian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Arunaggiri\n",
      "[nltk_data]     Pandian\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# stop_words = stopwords.words('english')\n",
    "# custom_stopwords = ['#studentloanforgiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cab2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to preprocess tweets\n",
    "\n",
    "# def preprocess_tweets(tweet, custom_stopwords):\n",
    "#     preprocessed_tweet = tweet\n",
    "#     # remove punctuation\n",
    "#     preprocessed_tweet.replace('[^w\\s]', '')\n",
    "#     # stop words removal\n",
    "#     preprocessed_tweet = \" \".join(word for word in preprocessed_tweet.split() if word not in stop_words)\n",
    "#     preprocessed_tweet = \" \".join(word for word in preprocessed_tweet.split() if word not in custom_stopwords)\n",
    "#     # lemmatization\n",
    "#     preprocessed_tweet = \" \".join(Word(word).lemmatize() for word in preprocessed_tweet.split())\n",
    "#     return(preprocessed_tweet)\n",
    "\n",
    "# df['Processed Tweet'] = df['Tweet'].apply(lambda x: preprocess_tweets(x, custom_stopwords))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f337c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# # Hack to avoid strange errors with textblob\n",
    "# from textblob import blob\n",
    "# def _penn_to_wordnet(tag):\n",
    "#     _wordnet = blob._wordnet\n",
    "#     \"\"\"Converts a Penn corpus tag into a Wordnet tag.\"\"\"\n",
    "#     if tag in (\"NN\", \"NNS\", \"NNP\", \"NNPS\"):\n",
    "#         return _wordnet.NOUN\n",
    "#     if tag in (\"JJ\", \"JJR\", \"JJS\"):\n",
    "#         return _wordnet.ADJ\n",
    "#     if tag in (\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"):\n",
    "#         return _wordnet.VERB\n",
    "#     if tag in (\"RB\", \"RBR\", \"RBS\"):\n",
    "#         return _wordnet.ADV\n",
    "#     # Print warning instead of returning None\n",
    "#     print('_penn_to_wordnet warning: no conversion found for ' + tag)\n",
    "#     return _wordnet.NOUN\n",
    "# blob._penn_to_wordnet = _penn_to_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "575b80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk as nltk\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa6282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Arunaggiri\n",
      "[nltk_data]     Pandian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c2745bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e233860",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc431e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "# Using regex to clean the data\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('fff.csv')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    #temp = re.sub(\"[^a-z0-9]\",\" \", temp) --> Doesn't remove numbers\n",
    "    temp = re.sub(\"[^a-z]\",\" \", temp)    \n",
    "    temp = temp.split()\n",
    "    temp = [w for w in temp if not w in stopwords]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fecc04a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arunaggiri Pandian\\AppData\\Local\\Temp\\ipykernel_39208\\2083338146.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(tweet) == np.float:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['want better get vote believe want would like old think',\n",
       " 'fact check send newsrooms story mental health everyone knows vote everone',\n",
       " 'distraction lets talk eminent domain farm seizures funding school districts stopping receiving backing collection debt company donors',\n",
       " 'question interviewer didnt ask nancy pelosi honor dilemma walk back claim president cant issue w congress damned either way amswers someone call respond',\n",
       " 'dark brandon administration student loan relief program putting pocket go yet',\n",
       " 'plan help students struggling payback outrageous loans includes working reform reduce college tuitions make sure future students problem never another loan forgiveness effort',\n",
       " 'woohoo hell think received thank',\n",
       " '',\n",
       " 'havent already',\n",
       " 'denying need would trying punish people seeking educated population advance interests america world taking conservatives']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [clean_tweet(tw) for tw in df['Tweet']]\n",
    "results[:10]\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21d662ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>United States</th>\n",
       "      <th>Date</th>\n",
       "      <th>User Name</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-23 23:43:33+00:00</td>\n",
       "      <td>unrealElunMosk</td>\n",
       "      <td>1.396130e+18</td>\n",
       "      <td>If you want your #studentloanforgiveness you b...</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/139613309...</td>\n",
       "      <td>want better get vote believe want would like o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-23 23:43:08+00:00</td>\n",
       "      <td>kevinpost</td>\n",
       "      <td>8.909302e+06</td>\n",
       "      <td>@GlennKesslerWP @ddale8 @PolitiFact \\nYou all ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159047739...</td>\n",
       "      <td>fact check send newsrooms story mental health ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-23 23:15:32+00:00</td>\n",
       "      <td>5731965i</td>\n",
       "      <td>8.190200e+17</td>\n",
       "      <td>@IAGovernor THIS IS A DISTRACTION. LETS TALK A...</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/879123411...</td>\n",
       "      <td>distraction lets talk eminent domain farm seiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-23 23:13:41+00:00</td>\n",
       "      <td>Flyonth85407338</td>\n",
       "      <td>9.866860e+17</td>\n",
       "      <td>@FoxNews The question the interviewer didn't a...</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/986696636...</td>\n",
       "      <td>question interviewer didnt ask nancy pelosi ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-23 23:04:06+00:00</td>\n",
       "      <td>TuscaloosaDems</td>\n",
       "      <td>4.701768e+07</td>\n",
       "      <td>Dark Brandon administration’s student loan rel...</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/157443155...</td>\n",
       "      <td>dark brandon administration student loan relie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   United States                       Date        User Name       User ID  \\\n",
       "0              0  2022-10-23 23:43:33+00:00   unrealElunMosk  1.396130e+18   \n",
       "1              1  2022-10-23 23:43:08+00:00        kevinpost  8.909302e+06   \n",
       "2              2  2022-10-23 23:15:32+00:00         5731965i  8.190200e+17   \n",
       "3              3  2022-10-23 23:13:41+00:00  Flyonth85407338  9.866860e+17   \n",
       "4              4  2022-10-23 23:04:06+00:00   TuscaloosaDems  4.701768e+07   \n",
       "\n",
       "                                               Tweet       Location  \\\n",
       "0  If you want your #studentloanforgiveness you b...  United States   \n",
       "1  @GlennKesslerWP @ddale8 @PolitiFact \\nYou all ...  United States   \n",
       "2  @IAGovernor THIS IS A DISTRACTION. LETS TALK A...  United States   \n",
       "3  @FoxNews The question the interviewer didn't a...  United States   \n",
       "4  Dark Brandon administration’s student loan rel...  United States   \n",
       "\n",
       "                                           Image URL  \\\n",
       "0  https://pbs.twimg.com/profile_images/139613309...   \n",
       "1  https://pbs.twimg.com/profile_images/159047739...   \n",
       "2  https://pbs.twimg.com/profile_images/879123411...   \n",
       "3  https://pbs.twimg.com/profile_images/986696636...   \n",
       "4  https://pbs.twimg.com/profile_images/157443155...   \n",
       "\n",
       "                                       Cleaned_Tweet  \n",
       "0  want better get vote believe want would like o...  \n",
       "1  fact check send newsrooms story mental health ...  \n",
       "2  distraction lets talk eminent domain farm seiz...  \n",
       "3  question interviewer didnt ask nancy pelosi ho...  \n",
       "4  dark brandon administration student loan relie...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new df from list\n",
    "df['Cleaned_Tweet'] = results\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
